
import streamlit as st
import os
import requests
from bs4 import BeautifulSoup
import certifi
from urllib.parse import urlparse, urljoin
from dotenv import load_dotenv
from openai import OpenAI
import pdfplumber
import pandas as pd


# === ğŸ‘¤ ãƒ­ã‚°ã‚¤ãƒ³èªè¨¼ã®è¿½åŠ  ===
import streamlit as st

USERNAME = "admin"
PASSWORD = "DDmirai2025!"

if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

if not st.session_state.authenticated:
    st.title("ğŸ”’ ãƒ­ã‚°ã‚¤ãƒ³")
    username = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼å")
    password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
    if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
        if username == USERNAME and password == PASSWORD:
            st.session_state.authenticated = True
        else:
            st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™")
    st.stop()  # ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãªã„é™ã‚Šä»¥é™ã¯æç”»ã•ã‚Œãªã„


# === åˆæœŸè¨­å®š ===
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
MODEL_NAME = os.getenv("OPENAI_MODEL", "gpt-4o")

# === å„ç¨®é–¢æ•° ===
def fetch_website_text(url):
    try:
        res = requests.get(url, timeout=5, verify=certifi.where())
        res.encoding = res.apparent_encoding
        soup = BeautifulSoup(res.text, 'html.parser')
        for tag in soup(["script", "style"]):
            tag.decompose()
        lines = [line.strip() for line in soup.get_text(separator="\n").splitlines()]
        return "\n".join(line for line in lines if line)
    except Exception as e:
        st.warning(f"{url} å–å¾—å¤±æ•—: {e}")
        return ""

def fetch_all_texts(base_url, max_pages=5):
    visited, to_visit, all_texts = set(), [base_url], []
    domain = urlparse(base_url).netloc
    while to_visit and len(visited) < max_pages:
        current_url = to_visit.pop(0)
        if current_url in visited:
            continue
        visited.add(current_url)
        text = fetch_website_text(current_url)
        if text:
            all_texts.append(text[:5000])
        try:
            res = requests.get(current_url, timeout=5, verify=certifi.where())
            soup = BeautifulSoup(res.text, 'html.parser')
            for a in soup.find_all("a", href=True):
                href = a['href']
                new_url = urljoin(base_url, href)
                if urlparse(new_url).netloc == domain:
                    if new_url not in visited and new_url not in to_visit:
                        to_visit.append(new_url)
        except Exception:
            continue
    return "\n\n".join(all_texts)

def extract_text_from_pdf(uploaded_pdf):
    text = ""
    try:
        with pdfplumber.open(uploaded_pdf) as pdf:
            for page in pdf.pages:
                text += page.extract_text() or ""
    except Exception as e:
        st.warning(f"PDFè§£æå¤±æ•—: {e}")
    return text

def suggest_segments_from_text(company_name, combined_text, issue_text, num_segments):
    prompt = f"""
ã‚ãªãŸã¯å„ªç§€ãªãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®ä¼æ¥­æƒ…å ±ã¨ã€æ—¢å­˜äº‹æ¥­ã®èª²é¡Œã«åŸºã¥ã„ã¦ã€ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°çš„ã«æœ‰æœ›ã¨æ€ã‚ã‚Œã‚‹é¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’{num_segments}å€‹ã€ã€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå + ãã®ç†ç”±ã€‘ã®å½¢å¼ã§ææ¡ˆã—ã¦ãã ã•ã„ã€‚

# å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
1. ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåï¼šã€‡ã€‡ã€‡ã€‡
   ç†ç”±ï¼šã€‡ã€‡ã€‡ã€‡
2. ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåï¼šãƒ»ãƒ»ãƒ»
   ç†ç”±ï¼šãƒ»ãƒ»ãƒ»

# ä¼šç¤¾å
{company_name}

# ä¼æ¥­æƒ…å ±
{combined_text}

# æ—¢å­˜äº‹æ¥­ã®èª²é¡Œ
{issue_text}
"""
    res = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": prompt}]
    )
    return res.choices[0].message.content

def generate_persona_for_segment(company_name, combined_text, segment_description, issue_text):
    prompt = f"""
ã‚ãªãŸã¯ãƒ—ãƒ­ã®ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®ä¼æ¥­æƒ…å ±ã¨äº‹æ¥­èª²é¡Œã«åŸºã¥ãã€æŒ‡å®šã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«æ²¿ã£ã¦ã€æˆ¦ç•¥çš„ã«æœ‰åŠ¹ãªãƒšãƒ«ã‚½ãƒŠã‚’1äººä½œæˆã—ã¦ãã ã•ã„ã€‚

# ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
{segment_description}

# ä¼šç¤¾å
{company_name}

# ä¼æ¥­æƒ…å ±ï¼ˆWeb/PDFï¼‰
{combined_text}

# æ—¢å­˜äº‹æ¥­ã®èª²é¡Œ
{issue_text}

# å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã“ã®æ§‹æˆãƒ»é †ç•ªã‚’å³å®ˆï¼‰
- åå‰: 
- å¹´é½¢, æ€§åˆ¥, è·æ¥­: 
- æ€§æ ¼: 
- å®¶æ—æ§‹æˆ: 
- ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«: 
- è¶£å‘³ãƒ»ä¾¡å€¤è¦³: 
- æ—¥å¸¸ã®æ‚©ã¿: 
- ã‚µãƒ¼ãƒ“ã‚¹åˆ©ç”¨ã‚·ãƒ¼ãƒ³: 
- è§£æ±ºã—ãŸã„èª²é¡Œ: 
- ã©ã“ã«ä¾¡å€¤ã‚’æ„Ÿã˜ã‚‹ã‹: 
- æƒ…å ±åé›†ãƒãƒ£ãƒãƒ«: 
- è³¼è²·æ±ºå®šãƒ—ãƒ­ã‚»ã‚¹: 
- ç«¶åˆã‚µãƒ¼ãƒ“ã‚¹: 
- ä¾¡æ ¼æ„Ÿåº¦: 
- å°å…¥æœŸå¾…åŠ¹æœ: 
- å°†æ¥å±•æœ›: 
"""
    res = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": prompt}]
    )
    return res.choices[0].message.content

def evaluate_persona_score(persona_text, idea_name, idea_desc):
    prompt = f"""
ã‚ãªãŸã¯ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ãƒªã‚µãƒ¼ãƒã®å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®ãƒšãƒ«ã‚½ãƒŠã¨äº‹æ¥­ã‚¢ã‚¤ãƒ‡ã‚¢ã®å†…å®¹ã‚’èª­ã¿ã€ã“ã®ã‚¢ã‚¤ãƒ‡ã‚¢ãŒã“ã®äººç‰©ã«ã¨ã£ã¦é­…åŠ›çš„ã‹ã©ã†ã‹ã‚’5æ®µéšã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

# ãƒšãƒ«ã‚½ãƒŠ
{persona_text}

# äº‹æ¥­ã‚¢ã‚¤ãƒ‡ã‚¢
åç§°: {idea_name}
å†…å®¹: {idea_desc}

# å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
- è©•ä¾¡ã‚¹ã‚³ã‚¢ï¼ˆ1ã€œ5ï¼‰: 
- ç†ç”±ï¼ˆ100æ–‡å­—ç¨‹åº¦ï¼‰:
"""
    res = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": prompt}]
    )
    return res.choices[0].message.content

# === UI ===
st.title("ğŸ§© ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆ ï¼‹ äº‹æ¥­è©•ä¾¡ãƒ„ãƒ¼ãƒ«")

company_name = st.text_input("â‘  ä¼æ¥­å")
website_url = st.text_input("â‘¡ Webã‚µã‚¤ãƒˆURLï¼ˆä»»æ„ï¼‰")
uploaded_pdfs = st.file_uploader("â‘¢ PDFè³‡æ–™ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆä»»æ„ï¼‰", type=["pdf"], accept_multiple_files=True)
issue_text = st.text_area("â‘£ æ—¢å­˜äº‹æ¥­ã®èª²é¡Œ")

persona_mode = st.radio("â‘¤ ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆãƒ¢ãƒ¼ãƒ‰", ["ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æŒ‡å®š", "AIãŒã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’è‡ªå‹•ææ¡ˆ"])
num_personas = st.slider("â‘¥ å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã”ã¨ã®ãƒšãƒ«ã‚½ãƒŠäººæ•°", 1, 3, 1)
num_segments_to_suggest = st.slider("â‘¦ ææ¡ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°ï¼ˆAIä½¿ç”¨æ™‚ï¼‰", 1, 6, 4)

if "segments" not in st.session_state:
    st.session_state.segments = ""
if "confirmed" not in st.session_state:
    st.session_state.confirmed = False
if "parsed_segments" not in st.session_state:
    st.session_state.parsed_segments = []
if "personas" not in st.session_state:
    st.session_state.personas = []
if "ideas" not in st.session_state:
    st.session_state.ideas = []

if persona_mode == "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æŒ‡å®š":
    st.session_state.segments = st.text_area("â‘§ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’1è¡Œãšã¤å…¥åŠ›", height=150)
    if st.session_state.segments:
        st.session_state.confirmed = True

if persona_mode == "AIãŒã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’è‡ªå‹•ææ¡ˆ" and st.button("ğŸ” AIã«ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ææ¡ˆã—ã¦ã‚‚ã‚‰ã†"):
    combined_text = ""
    if website_url:
        combined_text += fetch_all_texts(website_url)
    if uploaded_pdfs:
        for pdf in uploaded_pdfs:
            combined_text += extract_text_from_pdf(pdf)
    if company_name and issue_text and combined_text:
        raw_output = suggest_segments_from_text(company_name, combined_text, issue_text, num_segments_to_suggest)

        parsed_segments = []
        for block in raw_output.strip().split("\n"):
            if "ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåï¼š" in block:
                name = block.replace("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåï¼š", "").strip()
                parsed_segments.append({"name": name, "reason": ""})
            elif "ç†ç”±ï¼š" in block and parsed_segments:
                parsed_segments[-1]["reason"] = block.replace("ç†ç”±ï¼š", "").strip()

        st.session_state.segments = "\n".join([seg["name"] for seg in parsed_segments])
        st.session_state.parsed_segments = parsed_segments
        st.session_state.confirmed = False
        st.success("AIã«ã‚ˆã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆææ¡ˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚ç·¨é›†å¾Œã«ç¢ºå®šã—ã¦ãã ã•ã„ã€‚")

if st.session_state.parsed_segments and not st.session_state.confirmed:
    st.markdown("### ğŸ¤– AIãŒææ¡ˆã—ãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼ˆç†ç”±ã¤ãï¼‰")
    for i, seg in enumerate(st.session_state.parsed_segments, 1):
        st.markdown(f"**{i}. {seg['name']}**  \nğŸ“ ç†ç”±: {seg['reason']}")

if st.session_state.segments and not st.session_state.confirmed:
    st.text_area("ğŸ“ ç·¨é›†å¯èƒ½ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆä¸€è¦§ï¼ˆ1è¡Œãšã¤ï¼‰", value=st.session_state.segments, height=150, key="segments_editable")
    if st.button("âœ… ç·¨é›†æ¸ˆã¿ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç¢ºå®š"):
        st.session_state.segments = st.session_state.segments_editable
        st.session_state.confirmed = True
        st.success("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç¢ºå®šã—ã¾ã—ãŸã€‚")

# ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆ
if st.session_state.segments and st.session_state.confirmed and st.button("ğŸš€ ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆã‚’å®Ÿè¡Œ"):
    combined_text = ""
    if website_url:
        combined_text += fetch_all_texts(website_url)
    if uploaded_pdfs:
        for pdf in uploaded_pdfs:
            combined_text += extract_text_from_pdf(pdf)
    st.session_state.personas = []
    for seg in st.session_state.segments.split("\n"):
        for i in range(num_personas):
            persona = generate_persona_for_segment(company_name, combined_text, seg, issue_text)
            st.session_state.personas.append({"segment": seg, "text": persona})

# CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨äº‹æ¥­è©•ä¾¡åˆ¶å¾¡
uploaded_csv = st.file_uploader("CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆäº‹æ¥­ã‚¢ã‚¤ãƒ‡ã‚¢å, äº‹æ¥­å†…å®¹ï¼‰", type="csv")
if uploaded_csv:
    if st.button("ğŸ“¥ CSVã‹ã‚‰äº‹æ¥­ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’èª­ã¿è¾¼ã‚€"):
        df = pd.read_csv(uploaded_csv)
        for _, row in df.iterrows():
            st.session_state.ideas.append({
                "name": row["äº‹æ¥­ã‚¢ã‚¤ãƒ‡ã‚¢å"],
                "desc": row["äº‹æ¥­å†…å®¹"]
            })
        st.success("CSVã‹ã‚‰äº‹æ¥­ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")

idea_name = st.text_input("ğŸ†• äº‹æ¥­ã‚¢ã‚¤ãƒ‡ã‚¢å")
idea_desc = st.text_area("ğŸ“ äº‹æ¥­å†…å®¹", height=120)
if st.button("â• ã‚¢ã‚¤ãƒ‡ã‚¢è¿½åŠ "):
    if idea_name and idea_desc:
        st.session_state.ideas.append({"name": idea_name, "desc": idea_desc})
        st.success("äº‹æ¥­ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")

# è©•ä¾¡ãƒœã‚¿ãƒ³è¡¨ç¤º
if st.session_state.personas and st.session_state.ideas:
    if st.button("ğŸ§  ãƒšãƒ«ã‚½ãƒŠã”ã¨ã®äº‹æ¥­è©•ä¾¡ã‚’å®Ÿè¡Œ"):
        for persona in st.session_state.personas:
            st.subheader(f"ğŸ¯ {persona['segment']} å‘ã‘ãƒšãƒ«ã‚½ãƒŠã®è©•ä¾¡")
            for idea in st.session_state.ideas:
                result = evaluate_persona_score(persona["text"], idea["name"], idea["desc"])
                st.markdown(f"**ğŸ“ ã‚¢ã‚¤ãƒ‡ã‚¢åï¼š{idea['name']}**")
                st.code(result)
