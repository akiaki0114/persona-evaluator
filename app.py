import streamlit as st
import pandas as pd
import requests
from io import BytesIO
from openai import OpenAI
from dotenv import load_dotenv
import os
import certifi
import pdfplumber
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
from serpapi import GoogleSearch
from generate_pdf_report import generate_pdf_report
import re

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
MODEL_NAME = os.getenv("OPENAI_MODEL", "gpt-4o")

def run_with_spinner(label, func, *args, **kwargs):
    with st.spinner(label):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            st.error(f"{label} „Åß„Ç®„É©„Éº: {e}")
            return None

def get_official_site(company_name):
    search = GoogleSearch({
        "q": f"{company_name} ÂÖ¨Âºè„Çµ„Ç§„Éà",
        "hl": "ja",
        "api_key": os.getenv("SERPAPI_KEY")
    })
    results = search.get_dict()
    try:
        return results["organic_results"][0]["link"]
    except (KeyError, IndexError):
        return ""

def fetch_website_text(url):
    try:
        res = requests.get(url, timeout=5, verify=certifi.where())
        res.encoding = res.apparent_encoding
        soup = BeautifulSoup(res.text, 'html.parser')
        for script in soup(["script", "style"]):
            script.decompose()
        lines = [line.strip() for line in soup.get_text(separator="\n").splitlines()]
        return "\n".join(line for line in lines if line)
    except Exception as e:
        st.warning(f"{url} ÂèñÂæóÂ§±Êïó: {e}")
        return ""

def fetch_all_texts(base_url, max_pages=10):
    visited, to_visit, all_texts = set(), [base_url], []
    domain = urlparse(base_url).netloc
    while to_visit and len(visited) < max_pages:
        current_url = to_visit.pop(0)
        if current_url in visited:
            continue
        visited.add(current_url)
        text = fetch_website_text(current_url)
        if text:
            all_texts.append(text[:5000])
        try:
            res = requests.get(current_url, timeout=5, verify=certifi.where())
            res.encoding = res.apparent_encoding
            soup = BeautifulSoup(res.text, 'html.parser')
            for a in soup.find_all("a", href=True):
                href = a['href']
                new_url = urljoin(base_url, href)
                if urlparse(new_url).netloc == domain and new_url not in visited and new_url not in to_visit:
                    to_visit.append(new_url)
        except Exception:
            continue
    return "\n\n".join(all_texts)

def extract_text_from_pdf(uploaded_pdf):
    text = ""
    try:
        with pdfplumber.open(uploaded_pdf) as pdf:
            for page in pdf.pages:
                text += page.extract_text() or ""
    except Exception as e:
        st.warning(f"PDFËß£ÊûêÂ§±Êïó: {e}")
    return text

def generate_personas(company_name, combined_text):
    prompt = f"""
„ÅÇ„Å™„Åü„ÅØ„Éà„ÉÉ„ÉóÊà¶Áï•„Ç≥„É≥„Çµ„É´„Çø„É≥„ÉàÂÖº„Éû„Éº„Ç±„Çø„Éº„Åß„Åô„ÄÇ
‰ª•‰∏ã„ÅÆÊÉÖÂ†±„ÇíÂÖÉ„Å´„ÄÅ„Åì„ÅÆ‰ºöÁ§æ„ÅÆÈ°ßÂÆ¢ÔºàÊ∂àË≤ªËÄÖ„Åæ„Åü„ÅØÂèñÂºïÂÖàÔºâ„Å®„Åó„Å¶„ÅÆ„Éö„É´„ÇΩ„Éä„Çí4‰∫∫‰ΩúÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

ÈáçË¶Å:
- {company_name} „ÅÆÁ§æÂì°„ÇÑÈñ¢‰øÇËÄÖ„ÅØÂê´„ÇÅ„Å™„ÅÑ„ÄÇ
- „ÅÇ„Åè„Åæ„Åß„Åì„ÅÆ‰ºöÁ§æ„ÅÆÂïÜÂìÅ„Éª„Çµ„Éº„Éì„Çπ„ÇíÂà©Áî®„Åô„ÇãÈ°ßÂÆ¢ÂÉè„Åß„Åô„ÄÇ

# ‰ºöÁ§æÂêç
{company_name}

# Web„Çµ„Ç§„ÉàÊÉÖÂ†± + PDFË≥áÊñô
{combined_text}

## „Éö„É´„ÇΩ„Éä1„Äú4
- ÂêçÂâç
- Âπ¥ÈΩ¢, ÊÄßÂà•, ËÅ∑Ê•≠, ÊÄßÊ†º, ÂÆ∂ÊóèÊßãÊàê, Ë∂£Âë≥„Éª‰æ°ÂÄ§Ë¶≥, Êó•Â∏∏„ÅÆÊÇ©„Åø,
  „Çµ„Éº„Éì„ÇπÂà©Áî®„Ç∑„Éº„É≥, Ëß£Ê±∫„Åó„Åü„ÅÑË™≤È°å, „Å©„Åì„Å´ÊúÄ„ÇÇ‰æ°ÂÄ§„ÇíÊÑü„Åò„Çã„Åã,
  ÊÉÖÂ†±ÂèéÈõÜ„ÉÅ„É£„Éç„É´, Ë≥ºË≤∑Ê±∫ÂÆö„Éó„É≠„Çª„Çπ, Á´∂Âêà„Çµ„Éº„Éì„ÇπÂà©Áî®Áä∂Ê≥Å,
  ‰æ°Ê†ºÊÑüÂ∫¶, Â∞éÂÖ•ÂæåÊúüÂæÖROI, Èï∑Êúü„Éì„Ç∏„Éß„É≥
"""
    response = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content

def generate_persona_image(persona_desc):
    prompt = f"""
{persona_desc} „ÇíÂèÇËÄÉ„Å´„Åó„Åü30-50‰ª£„Éì„Ç∏„Éç„Çπ„Éë„Éº„ÇΩ„É≥„ÅÆÈ°ßÂÆ¢„ÅÆÊó•Â∏∏È¢®ÊôØ„ÅÆ„Çπ„Éä„ÉÉ„Éó„ÄÇ
Ëá™ÁÑ∂ÂÖâ„ÄÅÁîüÊ¥ªÊÑü„ÅÆ„ÅÇ„ÇãËÉåÊôØ„ÄÅ„É™„É©„ÉÉ„ÇØ„Çπ„Åó„ÅüË°®ÊÉÖ„ÄÇ
„É™„Ç¢„É´„Å™Ë≥™ÊÑü„ÄÅÊñáÂ≠ó„ÇÑ„É©„Éô„É´„Å™„Åó„ÄÅÂ∫ÉÂëä„Åß„ÅØ„Å™„Åè„Éâ„Ç≠„É•„É°„É≥„Çø„É™„ÉºÈ¢®„ÄÇ
"""
    img = client.images.generate(
        model="dall-e-3",
        prompt=prompt,
        size="1024x1024"
    )
    return img.data[0].url

def evaluate_persona_score(persona, idea_name, idea_content):
    prompt = f"""
„ÅÇ„Å™„Åü„ÅØ„Éö„É´„ÇΩ„ÉäÊú¨‰∫∫„ÅÆÊ∞óÊåÅ„Å°„Å´„Å™„Çä„Åç„Å£„Å¶„ÄÅ‰∏ãË®ò„ÅÆ‰∫ãÊ•≠„Ç¢„Ç§„Éá„Ç¢„Çí„ÄåËá™ÂàÜ„Å™„ÇâÊú¨ÂΩì„Å´‰Ωø„ÅÑ„Åü„ÅÑ„Åã/ÁîüÊ¥ª„Åå„Å©„ÅÜÂ∫É„Åå„Çã„Åã„Äç„ÅÆË¶≥ÁÇπ„ÅßÁèæÂÆüÁöÑ„Å´Ë©ï‰æ°„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
100ÁÇπÊ∫ÄÁÇπ„ÅßÁÇπÊï∞„Çí„Å§„Åë„ÄÅ„Åù„ÅÆÁêÜÁî±„Çí1Êñá„ÅßËø∞„Åπ„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
ÁÇπÊï∞„ÅØÂ∫É„Åå„Çä„ÇíÊåÅ„Åü„Åõ„Å¶ÔºàÈ´òÂæóÁÇπ„ÇÇÊôÇ„ÄÖÂá∫„Çã„Ç§„É°„Éº„Ç∏„ÅßÔºâ„ÄÅÂøñÂ∫¶„Åõ„Åö„Å´Ê≠£Áõ¥„Å´„ÄÅ„Å™„Çã„Åπ„ÅèÁîüÊ¥ª„ÅÆ‰∏≠„Åß„ÅÆÂà©Áî®„Ç§„É°„Éº„Ç∏„Å®Â∫É„Åå„Çä„Åæ„ÅßÊÉ≥ÂÉè„Åó„Å¶ÂõûÁ≠î„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

# „Éö„É´„ÇΩ„Éä
{persona}

# ‰∫ãÊ•≠„Ç¢„Ç§„Éá„Ç¢
ÂêçÁß∞: {idea_name}
ÂÜÖÂÆπ: {idea_content}

# Âá∫Âäõ„Éï„Ç©„Éº„Éû„ÉÉ„Éà
- „Çπ„Ç≥„Ç¢Ôºà100ÁÇπÊ∫ÄÁÇπ„ÉªÊï∞Â≠ó„ÅÆ„ÅøÔºâ
- ÁêÜÁî±Ôºà1Êñá„ÄÅÂà©Áî®„Ç∑„Éº„É≥„ÅÆÊÉ≥ÂÉè„ÉªÁîüÊ¥ª„Å∏„ÅÆÂ∫É„Åå„Çä„ÇíË∏è„Åæ„Åà„Å¶Ôºâ
"""
    response = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content

def evaluate_strategy_multiaxis(company_name, idea_name, idea_content):
    prompt = f"""
„ÅÇ„Å™„Åü„ÅØÊ•µ„ÇÅ„Å¶ÁèæÂÆüÁöÑ„Å™Êà¶Áï•„Ç≥„É≥„Çµ„É´„Çø„É≥„Éà„Åß„Åô„ÄÇ
‰∏ãË®ò„ÅÆ‰∫ãÊ•≠„Ç¢„Ç§„Éá„Ç¢„Çí„ÄåÂ∏ÇÂ†¥ÊÄß„Äç„ÄåÁ´∂‰∫âÂÑ™‰ΩçÊÄß„Äç„ÄåÂèéÁõäÊÄß„Äç„ÄåÂÆüÁèæÂèØËÉΩÊÄß„Äç„ÄåÊàêÈï∑ÊÄß„Äç„ÅÆ5Ëª∏„Åß100ÁÇπÊ∫ÄÁÇπ„ÅßË©ï‰æ°„Åó„ÄÅ„Åù„Çå„Åû„ÇåÁêÜÁî±„ÇíÁ∞°ÊΩî„Å´Ëø∞„Åπ„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
Ë°®Ë®ò„ÇÜ„Çå„Å™„ÅèÂøÖ„Åö‰∏ãË®ò„Éï„Ç©„Éº„Éû„ÉÉ„ÉàÈÄö„Çä„ÄÅÁÇπÊï∞„Å®ÁêÜÁî±„ÇíÂá∫Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

# ‰ºöÁ§æÂêç
{company_name}

# ‰∫ãÊ•≠„Ç¢„Ç§„Éá„Ç¢
ÂêçÁß∞: {idea_name}
ÂÜÖÂÆπ: {idea_content}

# Âá∫Âäõ„Éï„Ç©„Éº„Éû„ÉÉ„Éà
- Â∏ÇÂ†¥ÊÄß: xxÁÇπÔºàÁêÜÁî±: „Äú„Äú„ÄúÔºâ
- Á´∂‰∫âÂÑ™‰ΩçÊÄß: xxÁÇπÔºàÁêÜÁî±: „Äú„Äú„ÄúÔºâ
- ÂèéÁõäÊÄß: xxÁÇπÔºàÁêÜÁî±: „Äú„Äú„ÄúÔºâ
- ÂÆüÁèæÂèØËÉΩÊÄß: xxÁÇπÔºàÁêÜÁî±: „Äú„Äú„ÄúÔºâ
- ÊàêÈï∑ÊÄß: xxÁÇπÔºàÁêÜÁî±: „Äú„Äú„ÄúÔºâ
"""
    response = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content

def generate_new_potential_personas(company_name, existing_personas, idea_name, idea_content):
    persona_list_str = "\n".join([p[:400] for p in existing_personas])
    prompt = f"""
„ÅÇ„Å™„Åü„ÅØ„Éà„ÉÉ„ÉóÊà¶Áï•„Ç≥„É≥„Çµ„É´„Çø„É≥„Éà„Åß„Åô„ÄÇ
‰∏ãË®ò„ÅÆ‰∫ãÊ•≠„Ç¢„Ç§„Éá„Ç¢„ÅØ„ÄÅ„Åì„Çå„Åæ„Åß„ÅÆÈ°ßÂÆ¢Â±§„Å´„ÅØ„É™„Éº„ÉÅ„Åó„Å¶„ÅÑ„Å™„Åã„Å£„Åü‚ÄúÊñ∞„Åü„Å™ÊΩúÂú®È°ßÂÆ¢Â±§‚Äù„ÅÆÈñãÊãì„Å´„ÇÇ„Å§„Å™„Åå„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ

# ‰∫ãÊ•≠„Ç¢„Ç§„Éá„Ç¢
ÂêçÁß∞: {idea_name}
ÂÜÖÂÆπ: {idea_content}

# Êó¢Â≠òÈ°ßÂÆ¢„Éö„É´„ÇΩ„Éä‰∏ÄË¶ß
{persona_list_str}

Áµ∂ÂØæÊù°‰ª∂:
- {company_name}„ÅÆÁ§æÂì°„ÇÑÈñ¢‰øÇËÄÖ„ÅØÂê´„ÇÅ„Å™„ÅÑ„Åì„Å®
- Êó¢Â≠ò„Éö„É´„ÇΩ„Éä„Å®Â±ûÊÄß„ÇÑÁâπÂæ¥„ÅåÈáçË§á„Åó„Å™„ÅÑ„ÄÅÊñ∞„Åü„Å™È°ßÂÆ¢Â±§ÔºàÊΩúÂú®„Éã„Éº„Ç∫Ôºâ„Çí2ÂêçÂàÜ

## „Éö„É´„ÇΩ„ÉäÂá∫Âäõ„Éï„Ç©„Éº„Éû„ÉÉ„Éà
- ÂêçÂâç
- Âπ¥ÈΩ¢„ÉªÊÄßÂà•„ÉªËÅ∑Ê•≠„Éª‰æ°ÂÄ§Ë¶≥„ÉªÊó•Â∏∏„ÅÆÊÇ©„Åø„Éª„Åì„ÅÆ„Ç¢„Ç§„Éá„Ç¢„ÅßÊÉπ„Åã„Çå„ÇãÁêÜÁî±
"""
    response = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content

def extract_persona_names(persona_list):
    names = []
    for persona in persona_list:
        m = re.search(r'ÂêçÂâç[:Ôºö]\s*([^\n]+)', persona)
        if m:
            names.append(m.group(1).strip())
        else:
            m2 = re.search(r'[:Ôºö]\s*([^\sÔºà\(\-]+)', persona.split('\n')[0])
            if m2:
                names.append(m2.group(1))
            else:
                names.append(f"„Éö„É´„ÇΩ„Éä{len(names)+1}")
    return names

st.title("È°ßÂÆ¢„Éö„É´„ÇΩ„Éä√ó‰∫ãÊ•≠„Ç¢„Ç§„Éá„Ç¢Ë©ï‰æ°„ÉÑ„Éº„É´")

# STEP 1
st.header("STEP 1: ‰ºÅÊ•≠ÊÉÖÂ†±")
col1, col2 = st.columns(2)
company_name = col1.text_input("‚ë† ‰ºÅÊ•≠ÂêçÔºà‰æã: ‰∏âË∂ä‰ºäÂã¢‰∏πÔºâ")
manual_url = col2.text_input("‚ë° URL„ÇíÁõ¥Êé•ÊåáÂÆö")
uploaded_pdf = st.file_uploader("‚ë¢ ‰∏≠ÊúüÁµåÂñ∂Ë®àÁîª„ÇÑÊ±∫ÁÆóË≥áÊñô„Å™„Å©„ÅÆPDF„Ç¢„ÉÉ„Éó„É≠„Éº„ÉâÔºà‰ªªÊÑè„ÉªË§áÊï∞ÂèØÔºâ", type=["pdf"], accept_multiple_files=True)
generate_images = st.checkbox("„Éö„É´„ÇΩ„Éä„Ç§„É°„Éº„Ç∏„ÇÇÁîüÊàê„Åô„Çã")

if st.button("üöÄ STEP1: „Éö„É´„ÇΩ„Éä„ÇíÁîüÊàê„Çπ„Çø„Éº„Éà"):
    combined_text = ""
    url = get_official_site(company_name) if company_name and not manual_url else manual_url
    if url:
        web_text = run_with_spinner("Ë§áÊï∞„Éö„Éº„Ç∏„ÇØ„É≠„Éº„É´‰∏≠...", fetch_all_texts, url)
        combined_text += web_text + "\n"

    if uploaded_pdf:
        for pdf_file in uploaded_pdf:
            pdf_text = run_with_spinner(f"{pdf_file.name} „ÇíËß£Êûê‰∏≠...", extract_text_from_pdf, pdf_file)
            combined_text += pdf_text + "\n"

    combined_text = combined_text[:60000]

    if combined_text:
        personas_text = run_with_spinner("„Éö„É´„ÇΩ„ÉäÁîüÊàê‰∏≠...", generate_personas, company_name or manual_url, combined_text)
        if not personas_text:
            st.error("„Éö„É´„ÇΩ„ÉäÁîüÊàê„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ„ÇÇ„ÅÜ‰∏ÄÂ∫¶Ë©¶„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
        else:
            persona_list = personas_text.split("## „Éö„É´„ÇΩ„Éä")[1:]
            persona_images, persona_images_bytes = [], []
            for i, persona in enumerate(persona_list, start=1):
                if generate_images:
                    img_url = run_with_spinner(f"„Éö„É´„ÇΩ„Éä{i} „ÅÆ„Ç§„É°„Éº„Ç∏ÁîüÊàê‰∏≠...", generate_persona_image, persona)
                    persona_images.append(img_url)
                    try:
                        img_bytes = requests.get(img_url, verify=False).content
                        persona_images_bytes.append(BytesIO(img_bytes))
                    except Exception as e:
                        st.warning(f"ÁîªÂÉè„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÂ§±Êïó: {e}")
                        persona_images_bytes.append(None)
                else:
                    persona_images.append(None)
                    persona_images_bytes.append(None)
            st.session_state["persona_list"] = persona_list
            st.session_state["persona_images"] = persona_images
            st.session_state["persona_images_bytes"] = persona_images_bytes
            st.success("‚úÖ „Éö„É´„ÇΩ„ÉäÁîüÊàêÂÆå‰∫ÜÔºÅ")
    else:
        st.warning("‰ºÅÊ•≠ÊÉÖÂ†±ÔºàWeb / PDFÔºâ„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")

if "persona_list" in st.session_state:
    st.header("„ÄêÁîüÊàê„Åï„Çå„Åü„Éö„É´„ÇΩ„Éä„Äë")
    persona_names = extract_persona_names(st.session_state["persona_list"])
    for i, (persona, img_url, name) in enumerate(zip(st.session_state["persona_list"], st.session_state["persona_images"], persona_names), start=1):
        cols = st.columns([1,3])
        with cols[0]:
            if img_url:
                st.image(img_url, caption=f"{name}")
        with cols[1]:
            st.text(persona.strip()[:1000] + "...")

# STEP 2
st.header("STEP 2: ‰∫ãÊ•≠„Ç¢„Ç§„Éá„Ç¢ÂÖ•ÂäõÔºàË§áÊï∞ÂèØÔºâ")
if "idea_texts" not in st.session_state:
    st.session_state["idea_texts"] = [("", "")]
if "add_idea_flag" not in st.session_state:
    st.session_state.add_idea_flag = False

uploaded_file = st.file_uploader("CSV„Ç¢„ÉÉ„Éó„É≠„Éº„ÉâÔºà‰∫ãÊ•≠„Ç¢„Ç§„Éá„Ç¢Âêç, ‰∫ãÊ•≠ÂÜÖÂÆπÔºâ", type=["csv"])
ideas = []

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    for _, row in df.iterrows():
        ideas.append((row["‰∫ãÊ•≠„Ç¢„Ç§„Éá„Ç¢Âêç"], row["‰∫ãÊ•≠ÂÜÖÂÆπ"]))
else:
    for i, (name, content) in enumerate(st.session_state["idea_texts"]):
        name = st.text_input(f"‰∫ãÊ•≠„Ç¢„Ç§„Éá„Ç¢{i+1} ÂêçÁß∞", value=name, key=f"idea_name_{i}")
        content = st.text_area(f"‰∫ãÊ•≠„Ç¢„Ç§„Éá„Ç¢{i+1} ÂÜÖÂÆπ", value=content, key=f"idea_content_{i}")
        st.session_state["idea_texts"][i] = (name, content)

    if st.button("‰∫ãÊ•≠„Ç¢„Ç§„Éá„Ç¢„ÇíËøΩÂä†"):
        st.session_state.add_idea_flag = True

    if st.session_state.add_idea_flag:
        st.session_state["idea_texts"].append(("", ""))
        st.session_state.add_idea_flag = False
        st.rerun()

    ideas = [idea for idea in st.session_state["idea_texts"] if idea[0] and idea[1]]

if st.button("üöÄ STEP2: ÂÖ®„Ç¢„Ç§„Éá„Ç¢„ÇíË©ï‰æ°"):
    persona_list = st.session_state.get("persona_list", [])
    persona_images_bytes = st.session_state.get("persona_images_bytes", [])
    persona_names = extract_persona_names(persona_list)
    if persona_list and ideas:
        records = []
        strategy_eval_dict = {}
        new_potential_personas_dict = {}
        for idea_name, idea_content in ideas:
            result_row = {"‰∫ãÊ•≠„Ç¢„Ç§„Éá„Ç¢Âêç": idea_name}
            # ÂêÑ„Éö„É´„ÇΩ„ÉäÂèóÂÆπÊÄßË©ï‰æ°
            for i, persona in enumerate(persona_list, start=1):
                eval_result = run_with_spinner(f"{idea_name} √ó {persona_names[i-1]} ÂèóÂÆπÊÄßË©ï‰æ°‰∏≠...", evaluate_persona_score, "## „Éö„É´„ÇΩ„Éä"+persona, idea_name, idea_content)
                try:
                    score_line = next(line for line in eval_result.splitlines() if "„Çπ„Ç≥„Ç¢" in line or "ÁÇπ" in line)
                    score = re.search(r'(\d+)', score_line).group(1)
                except Exception:
                    score = "N/A"
                try:
                    reason_line = next(line for line in eval_result.splitlines() if "ÁêÜÁî±" in line)
                    reason = reason_line.split(":")[-1].strip()
                except StopIteration:
                    reason = ""
                result_row[f"„Éö„É´„ÇΩ„Éä{i}„Çπ„Ç≥„Ç¢"] = score
                result_row[f"„Éö„É´„ÇΩ„Éä{i}ÁêÜÁî±"] = reason

            # Â§öËª∏Êà¶Áï•Ë©ï‰æ°
            multi_eval_result = run_with_spinner(f"{idea_name} Â§öËª∏Êà¶Áï•Ë©ï‰æ°‰∏≠...", evaluate_strategy_multiaxis, company_name, idea_name, idea_content)
            strategy_eval_dict[idea_name] = multi_eval_result

            # Êñ∞Ë¶èÊΩúÂú®È°ßÂÆ¢„Éö„É´„ÇΩ„ÉäÁîüÊàê
            new_persona_text = run_with_spinner(
                f"{idea_name}Âêë„Åë Êñ∞Ë¶èÊΩúÂú®È°ßÂÆ¢„Éö„É´„ÇΩ„ÉäÁîüÊàê‰∏≠...",
                generate_new_potential_personas, company_name, persona_list, idea_name, idea_content
            )
            new_potential_personas_dict[idea_name] = new_persona_text
            records.append(result_row)

        df = pd.DataFrame(records)
        st.session_state["result_df"] = df
        st.session_state["latest_persona_list"] = persona_list
        st.session_state["latest_persona_images_bytes"] = persona_images_bytes
        st.session_state["new_potential_personas"] = new_potential_personas_dict
        st.session_state["strategy_eval_dict"] = strategy_eval_dict
        st.dataframe(df)
        st.header("„ÄêÂ§öËª∏Êà¶Áï•Ë©ï‰æ°„Äë")
        for idea_name, eval_text in strategy_eval_dict.items():
            st.markdown(f"### ‚ñ† {idea_name}")
            st.markdown(f"<pre>{eval_text}</pre>", unsafe_allow_html=True)
        st.header("„ÄêÊñ∞Ë¶èÊΩúÂú®È°ßÂÆ¢„Éö„É´„ÇΩ„Éä„Äë")
        for idea_name, new_pers in new_potential_personas_dict.items():
            st.markdown(f"### ‚ñ† {idea_name}")
            st.markdown(f"<pre>{new_pers}</pre>", unsafe_allow_html=True)
    else:
        st.warning("„Åæ„ÅöSTEP1„ÇíÂÆüË°å„Åó„Éö„É´„ÇΩ„Éä„ÇíÁîüÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")

if "result_df" in st.session_state and not st.session_state["result_df"].empty:
    st.header("„Äê„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Äë")
    if st.button("PDF„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ"):
        pdf = generate_pdf_report(
            st.session_state["latest_persona_list"],
            st.session_state["result_df"],
            company_name or "manual",
            st.session_state["latest_persona_images_bytes"],
            st.session_state.get("new_potential_personas", None),
            st.session_state.get("strategy_eval_dict", None),
        )
        st.download_button("üìÑ PDF„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ", data=pdf, file_name=f"{company_name or 'manual'}_Ë©ï‰æ°„É¨„Éù„Éº„Éà.pdf", mime="application/pdf")
    if st.button("CSV„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ"):
        csv = st.session_state["result_df"].to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
        st.download_button("CSV„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÔºàUTF-8 ExcelÂØæÂøúÔºâ", data=csv, file_name=f"{company_name or 'manual'}_Ë©ï‰æ°ÁµêÊûú.csv", mime='text/csv')
else:
    st.info("„Åæ„ÅöÂÖ®„Ç¢„Ç§„Éá„Ç¢Ë©ï‰æ°„ÇíÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
